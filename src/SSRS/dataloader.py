import os
import numpy as np
import tensorflow as tf
import pandas as pd


class Sample:
    def __init__(self, data, label):
        self.data = data
        self.label = label
        self.confidence = None  # ç½®ä¿¡åº¦
        self.lsa = None
        self.dsa = None
        self.partition = None
        self.predicted_label = None


class DataLoader:
    def __init__(self, model_path='../../data/model/modelA.h5',
                 data_dir='../../data/dataset/MNIST/raw', csv_path=None):
        print("------------------------Loading Data------------------------")
        self.model_path = model_path
        self.data_dir = data_dir
        self.csv_path = csv_path
        self.samples = None
        self.model = None
        if csv_path is None:
            self.load_data_from_mnist()
        else:
            self.load_data_from_csv()

        print("------------------------Data loaded successfully!------------------------\n")

    def load_data_from_csv(self):
        print("Loading data from csv...")
        # csvçš„è¡¨å¤´ä¸º: ID,outcome,SUT,confidence,dsa,lsa,uniform
        csv = pd.read_csv(self.csv_path)  # è¯»å–csvæ–‡ä»¶
        samples = []
        for index, row in csv.iterrows():
            sample = Sample(data=None, label=row['SUT'])
            sample.confidence = 1 - row['confidence']  # åŸæ–‡å‡è®¾è¾…åŠ©å˜é‡ä¸å‡†ç¡®æ€§è´Ÿç›¸å…³(å³è¾…åŠ©å˜é‡$ğœ’_i$çš„å€¼è¶Šå¤§, DNNæ¨¡å‹å¯¹æ ·æœ¬$d_i$é¢„æµ‹çš„ç½®ä¿¡åº¦è¶Šä½, é‚£ä¹ˆDNNè¶Šæœ‰å¯èƒ½äº§ç”Ÿè¯¯åˆ¤), å› æ­¤$ğœ’_i = 1- C_{d_i}$
            sample.lsa = row['lsa']
            sample.dsa = row['dsa']
            sample.predicted_label = row['SUT'] if row['outcome'] == 'Pass' else -1
            samples.append(sample)
        self.samples = samples

    def load_data_from_mnist(self):
        self.model = tf.keras.models.load_model(self.model_path)
        self.load_operational_dataset()
        self.load_confidence()
        self.load_dsa()
        self.load_lsa()

    def load_mnist_images(self, file_path):
        import struct
        with open(file_path, 'rb') as file:
            magic, num, rows, cols = struct.unpack(">IIII", file.read(16))
            images = np.fromfile(file, dtype=np.uint8).reshape(num, rows, cols)
        return images

    def load_mnist_labels(self, file_path):
        import struct
        with open(file_path, 'rb') as file:
            magic, num = struct.unpack(">II", file.read(8))
            labels = np.fromfile(file, dtype=np.uint8)
        return labels

    def load_operational_dataset(self):
        # æ‹¼æ¥è®­ç»ƒé›†, æµ‹è¯•é›†å’Œå¯¹åº”æ ‡ç­¾æ–‡ä»¶çš„è·¯å¾„
        train_images_path = os.path.join(self.data_dir, 'train-images-idx3-ubyte')
        train_labels_path = os.path.join(self.data_dir, 'train-labels-idx1-ubyte')
        test_images_path = os.path.join(self.data_dir, 't10k-images-idx3-ubyte')
        test_labels_path = os.path.join(self.data_dir, 't10k-labels-idx1-ubyte')
        # åŠ è½½MNISTå®˜æ–¹åˆ’åˆ†çš„æµ‹è¯•é›†å’Œè®­ç»ƒé›†
        train_images = self.load_mnist_images(train_images_path)
        train_labels = self.load_mnist_labels(train_labels_path)
        test_images = self.load_mnist_images(test_images_path)
        test_labels = self.load_mnist_labels(test_labels_path)

        # å°†MNISTå®˜æ–¹åˆ’åˆ†çš„å…¨éƒ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„å‰500ä¸ªæ ·æœ¬ä½œä¸ºæ“ä½œé›†
        operational_images = np.concatenate([train_images, test_images[:500]])  # 60500
        operational_labels = np.concatenate([train_labels, test_labels[:500]])  # 60500

        # åˆ›å»ºSampleç±»çš„åˆ—è¡¨
        samples = []
        for image_data, label_data in zip(operational_images, operational_labels):
            # åˆ›å»ºä¸€ä¸ªSampleå¯¹è±¡å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            sample = Sample(data=image_data, label=label_data)
            samples.append(sample)
        self.samples = samples

    def load_confidence(self):
        print("Loading confidence...")
        # ç¡®ä¿ TensorFlow èƒ½ä½¿ç”¨ GPU
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                # è®¾ç½® TensorFlow ä½¿å…¶åœ¨æ¯ä¸ª GPU ä¸Šå°½å¯èƒ½å¤šåœ°ä½¿ç”¨å†…å­˜
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
            except RuntimeError as e:
                print("Error setting GPU: ", e)

        # å°†Sampleå¯¹è±¡åˆ—è¡¨ä¸­çš„æ•°æ®æå–å‡ºæ¥å¹¶è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        images = np.array([sample.data for sample in self.samples], dtype=np.float32)
        # images = images / 255.0  # å°†åƒç´ å€¼å½’ä¸€åŒ–åˆ°[0, 1]ä¹‹é—´
        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹åæ›´æ–°æ¯ä¸ªSampleå¯¹è±¡çš„ç½®ä¿¡åº¦
        predictions = self.model.predict(images)
        confidences = np.max(predictions, axis=1)
        for sample, confidence in zip(self.samples, confidences):
            sample.confidence = 1 - confidence  # åŸæ–‡å‡è®¾è¾…åŠ©å˜é‡ä¸å‡†ç¡®æ€§è´Ÿç›¸å…³(å³è¾…åŠ©å˜é‡$ğœ’_i$çš„å€¼è¶Šå¤§, DNNæ¨¡å‹å¯¹æ ·æœ¬$d_i$é¢„æµ‹çš„ç½®ä¿¡åº¦è¶Šä½, é‚£ä¹ˆDNNè¶Šæœ‰å¯èƒ½äº§ç”Ÿè¯¯åˆ¤), å› æ­¤$ğœ’_i = 1- C_{d_i}$

    def load_lsa(self):
        pass

    def load_dsa(self):
        pass
